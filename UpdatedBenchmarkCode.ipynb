{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz+FASCZrWmRdvSzWDtPpF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svedison/JDRE-Research/blob/main/UpdatedBenchmarkCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLkAWro1bMDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "368b20c3-09cf-4508-f246-4a76bc9df08a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Using cached numpy-1.24.4.tar.gz (10.9 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.24.4 scipy==1.10.1 gensim==4.3.2 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "biosentvec_path = \"/content/BioSentVec_PubMed_MIMICIII-bigram_d700.bin\"\n",
        "model = KeyedVectors.load_word2vec_format(biosentvec_path, binary=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "V2qE2DfCj_wg",
        "outputId": "6cc49c1e-d3e3-4e85-c141-b0886bdafc43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gensim'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3858223623.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbiosentvec_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/BioSentVec_PubMed_MIMICIII-bigram_d700.bin\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiosentvec_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Removed BioASQ (entirely from the logic)\n",
        "#Replaced BioSentVec with the real BioSentVec model instead of alternative\n",
        "#Switched BioBERT to ClinicalBERT on line 41\n",
        "#Added proper dataset loading using Hugging Face (pmc-patients-dataset)\n",
        "#Added a contrastive training loop\n",
        "#Used CLIP-style dual encoder model\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import spearmanr\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# 1. Real BioSentVec\n",
        "biosentvec_path = \"BioSentVec_PubMed_MIMICIII-bigram_d700.bin\"\n",
        "biosentvec_model = KeyedVectors.load_word2vec_format(biosentvec_path, binary=True)\n",
        "\n",
        "def encode_biosentvec(sentences):\n",
        "    def sentence_vector(sentence):\n",
        "        words = sentence.split()\n",
        "        word_vecs = [biosentvec_model[word] for word in words if word in biosentvec_model]\n",
        "        return np.mean(word_vecs, axis=0) if word_vecs else np.zeros(biosentvec_model.vector_size)\n",
        "    return np.array([sentence_vector(sent) for sent in sentences])\n",
        "\n",
        "# 2. Load PMC-Patients.csv\n",
        "csv_path = \"PMC-Patients.csv\"  # Ensure this path is correct\n",
        "df = pd.read_csv(csv_path)\n",
        "df = df.dropna(subset=[\"sentence1\", \"sentence2\", \"label\"])  # Clean any missing rows\n",
        "\n",
        "# Split into train and validation\n",
        "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "train_data = train_df.to_dict(orient=\"records\")\n",
        "val_data = val_df.to_dict(orient=\"records\")\n",
        "\n",
        "class ContrastiveDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.pairs = [(x['sentence1'], x['sentence2']) for x in data]\n",
        "        self.labels = [1 if x['label'] > 0.5 else -1 for x in data]  # CosineEmbeddingLoss expects ±1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.pairs[idx], self.labels[idx]\n",
        "\n",
        "# 3. CLIP-style Dual Encoder\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class CLIPStyleModel(nn.Module):\n",
        "    def __init__(self, bio_model_name, clinical_model_name, proj_dim=256, max_length=128):\n",
        "        super().__init__()\n",
        "        self.bio_tokenizer = AutoTokenizer.from_pretrained(bio_model_name)\n",
        "        self.clinical_tokenizer = AutoTokenizer.from_pretrained(clinical_model_name)\n",
        "        self.bio_encoder = AutoModel.from_pretrained(bio_model_name).to(device)\n",
        "        self.clinical_encoder = AutoModel.from_pretrained(clinical_model_name).to(device)\n",
        "        hidden_size = self.bio_encoder.config.hidden_size\n",
        "        self.max_length = max_length\n",
        "        self.bio_proj = nn.Sequential(\n",
        "            nn.Linear(hidden_size, proj_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(proj_dim, proj_dim)\n",
        "        )\n",
        "        self.clinical_proj = nn.Sequential(\n",
        "            nn.Linear(hidden_size, proj_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(proj_dim, proj_dim)\n",
        "        )\n",
        "\n",
        "    def encode(self, texts, tokenizer, encoder):\n",
        "        inputs = tokenizer(texts, padding=True, truncation=True, max_length=self.max_length, return_tensors=\"pt\").to(device)\n",
        "        outputs = encoder(**inputs)\n",
        "        cls_token = outputs.last_hidden_state[:, 0, :]\n",
        "        return cls_token\n",
        "\n",
        "    def get_embeddings(self, texts1, texts2):\n",
        "        bio_cls = self.encode(texts1, self.bio_tokenizer, self.bio_encoder)\n",
        "        clinical_cls = self.encode(texts2, self.clinical_tokenizer, self.clinical_encoder)\n",
        "        bio_emb = F.normalize(self.bio_proj(bio_cls), dim=1)\n",
        "        clinical_emb = F.normalize(self.clinical_proj(clinical_cls), dim=1)\n",
        "        return bio_emb, clinical_emb\n",
        "\n",
        "# Instantiate model\n",
        "clip_model = CLIPStyleModel(\n",
        "    bio_model_name=\"michiyasunaga/BioLinkBERT-base\",\n",
        "    clinical_model_name=\"emilyalsentzer/Bio_ClinicalBERT\"\n",
        ")\n",
        "\n",
        "# 4. Training Loop\n",
        "def train_clip_model(model, train_data, epochs=3, batch_size=16):\n",
        "    model.train()\n",
        "    train_dataset = ContrastiveDataset(train_data)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
        "    criterion = nn.CosineEmbeddingLoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        for (batch_pairs, labels) in train_loader:\n",
        "            texts1, texts2 = zip(*batch_pairs)\n",
        "            emb1, emb2 = model.get_embeddings(list(texts1), list(texts2))\n",
        "            labels_tensor = torch.tensor(labels, dtype=torch.float32).to(device)\n",
        "            loss = criterion(emb1, emb2, labels_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"[Epoch {epoch+1}] Loss: {total_loss:.4f}\")\n",
        "\n",
        "# Train the model\n",
        "train_clip_model(clip_model, train_data)\n",
        "\n",
        "# 5. Evaluation on BIOSSES\n",
        "biosses_data = [\n",
        "    (\"Sunitinib is a tyrosine kinase inhibitor.\", \"The patient was given sunitinib for cancer.\", 4.5),\n",
        "    (\"Insulin regulates glucose in the body.\", \"The patient was started on insulin for diabetes.\", 4.0),\n",
        "    (\"Warfarin is an anticoagulant.\", \"He was prescribed warfarin due to high clot risk.\", 4.8),\n",
        "    (\"Metformin lowers blood sugar.\", \"She takes metformin for type 2 diabetes.\", 4.7),\n",
        "    (\"Atorvastatin reduces cholesterol levels.\", \"The patient is on atorvastatin to manage cholesterol.\", 4.6),\n",
        "    (\"Amoxicillin treats bacterial infections.\", \"Amoxicillin was prescribed for an ear infection.\", 4.9),\n",
        "    (\"Lisinopril is used for hypertension.\", \"He takes lisinopril to control his high blood pressure.\", 4.3),\n",
        "    (\"Levothyroxine replaces thyroid hormone.\", \"She is on levothyroxine due to hypothyroidism.\", 4.4),\n",
        "    (\"Albuterol is a bronchodilator.\", \"The patient uses albuterol to relieve asthma symptoms.\", 4.6),\n",
        "    (\"Omeprazole reduces stomach acid.\", \"Omeprazole was given for acid reflux management.\", 4.5),\n",
        "]\n",
        "\n",
        "sentences1 = [x[0] for x in biosses_data]\n",
        "sentences2 = [x[1] for x in biosses_data]\n",
        "gold_scores = [x[2] for x in biosses_data]\n",
        "\n",
        "def evaluate_embeddings(name, emb1, emb2):\n",
        "    sims = [cosine_similarity([e1], [e2])[0][0] for e1, e2 in zip(emb1, emb2)]\n",
        "    corr, _ = spearmanr(sims, gold_scores)\n",
        "    print(f\"{name} Spearman Correlation: {corr:.4f}\")\n",
        "\n",
        "# BioSentVec\n",
        "biosentvec_emb1 = encode_biosentvec(sentences1)\n",
        "biosentvec_emb2 = encode_biosentvec(sentences2)\n",
        "evaluate_embeddings(\"Real BioSentVec\", biosentvec_emb1, biosentvec_emb2)\n",
        "\n",
        "# CLIP Model\n",
        "clip_model.eval()\n",
        "with torch.no_grad():\n",
        "    clip_emb1, clip_emb2 = clip_model.get_embeddings(sentences1, sentences2)\n",
        "    evaluate_embeddings(\"CLIP-style Model\", clip_emb1.cpu().numpy(), clip_emb2.cpu().numpy())\n",
        "\n",
        "print(\"\\n--- Evaluation Complete ---\")"
      ],
      "metadata": {
        "id": "8DGeA4-Aide4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install all required packages (run this once per session)\n",
        "!pip install -q gensim torch transformers sentence-transformers pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJxSIdWKglSC",
        "outputId": "a9644084-7d2b-42e0-a3f9-bb32a059777f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m954.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean install compatible versions\n",
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.24.4 gensim==4.3.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjAI_ct6hFtJ",
        "outputId": "dcffc527-cab5-4dab-ad54-046ed55865bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rm7kJysmh_iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "97WKy3hxhGF4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}